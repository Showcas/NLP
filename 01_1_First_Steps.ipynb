{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Showcas/NLP/blob/main/01_1_First_Steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7v_CYjoi-JO"
      },
      "source": [
        "# Natural Language Processing with Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "boTUWVMtuUZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cffc3dd1-737c-4fc4-ca20-2156a704acf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "accelerate==1.3.0\n",
            "aiohappyeyeballs==2.4.6\n",
            "aiohttp==3.11.12\n",
            "aiosignal==1.3.2\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.23\n",
            "albumentations==2.0.4\n",
            "ale-py==0.10.1\n",
            "altair==5.5.0\n",
            "annotated-types==0.7.0\n",
            "anyio==3.7.1\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.6.0\n",
            "arviz==0.20.0\n",
            "astropy==7.0.1\n",
            "astropy-iers-data==0.2025.2.10.0.33.26\n",
            "astunparse==1.6.3\n",
            "atpublic==4.1.0\n",
            "attrs==25.1.0\n",
            "audioread==3.0.1\n",
            "autograd==1.7.0\n",
            "babel==2.17.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.13.3\n",
            "betterproto==2.0.0b6\n",
            "bigframes==1.36.0\n",
            "bigquery-magics==0.5.0\n",
            "bleach==6.2.0\n",
            "blinker==1.9.0\n",
            "blis==0.7.11\n",
            "blosc2==3.1.0\n",
            "bokeh==3.6.3\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.44\n",
            "branca==0.8.1\n",
            "CacheControl==0.14.2\n",
            "cachetools==5.5.1\n",
            "catalogue==2.0.10\n",
            "certifi==2025.1.31\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.1\n",
            "chex==0.1.88\n",
            "clarabel==0.10.0\n",
            "click==8.1.8\n",
            "cloudpathlib==0.20.0\n",
            "cloudpickle==3.1.1\n",
            "cmake==3.31.4\n",
            "cmdstanpy==1.2.5\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.6\n",
            "contourpy==1.3.1\n",
            "cramjam==2.9.1\n",
            "cryptography==43.0.3\n",
            "cuda-python==12.6.0\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==13.3.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.6.0\n",
            "cycler==0.12.1\n",
            "cyipopt==1.5.0\n",
            "cymem==2.0.11\n",
            "Cython==3.0.12\n",
            "dask==2024.10.0\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.4.1\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "Deprecated==1.2.18\n",
            "diffusers==0.32.2\n",
            "distro==1.9.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.9\n",
            "dnspython==2.7.0\n",
            "docker-pycreds==0.4.0\n",
            "docstring_parser==0.16\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.1.2\n",
            "duckdb==1.1.3\n",
            "earthengine-api==1.5.2\n",
            "easydict==1.13\n",
            "editdistance==0.8.1\n",
            "eerepr==0.1.0\n",
            "einops==0.8.1\n",
            "email_validator==2.2.0\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.12.0\n",
            "etuples==0.3.9\n",
            "Farama-Notifications==0.0.4\n",
            "fastai==2.7.18\n",
            "fastcore==1.7.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.3\n",
            "filelock==3.17.0\n",
            "firebase-admin==6.6.0\n",
            "Flask==3.1.0\n",
            "flatbuffers==25.2.10\n",
            "flax==0.10.3\n",
            "folium==0.19.4\n",
            "fonttools==4.56.0\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.5.0\n",
            "fsspec==2024.10.0\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2024.10.0\n",
            "GDAL==3.6.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.1\n",
            "gensim==4.3.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==1.0.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.12\n",
            "GitPython==3.1.44\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.15\n",
            "google-api-core==2.19.2\n",
            "google-api-python-client==2.160.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.1\n",
            "google-cloud-aiplatform==1.79.0\n",
            "google-cloud-bigquery==3.25.0\n",
            "google-cloud-bigquery-connection==1.17.0\n",
            "google-cloud-bigquery-storage==2.28.0\n",
            "google-cloud-bigtable==2.28.1\n",
            "google-cloud-core==2.4.1\n",
            "google-cloud-dataproc==5.17.0\n",
            "google-cloud-datastore==2.20.2\n",
            "google-cloud-firestore==2.20.0\n",
            "google-cloud-functions==1.19.0\n",
            "google-cloud-iam==2.18.0\n",
            "google-cloud-language==2.16.0\n",
            "google-cloud-pubsub==2.25.0\n",
            "google-cloud-resource-manager==1.14.0\n",
            "google-cloud-spanner==3.51.0\n",
            "google-cloud-storage==2.19.0\n",
            "google-cloud-translate==3.19.0\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.6.0\n",
            "google-genai==0.8.0\n",
            "google-generativeai==0.8.4\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "google-spark-connect==0.5.2\n",
            "googleapis-common-protos==1.67.0\n",
            "googledrivedownloader==1.1.0\n",
            "graphviz==0.20.3\n",
            "greenlet==3.1.1\n",
            "grpc-google-iam-v1==0.14.0\n",
            "grpc-interceptor==0.15.4\n",
            "grpcio==1.70.0\n",
            "grpcio-status==1.62.3\n",
            "grpclib==0.4.7\n",
            "gspread==6.1.4\n",
            "gspread-dataframe==4.0.0\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "gymnasium==1.0.0\n",
            "h11==0.14.0\n",
            "h2==4.2.0\n",
            "h5netcdf==1.5.0\n",
            "h5py==3.12.1\n",
            "highspy==1.9.0\n",
            "holidays==0.66\n",
            "holoviews==1.20.0\n",
            "hpack==4.1.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.7\n",
            "httpimport==1.4.0\n",
            "httplib2==0.22.0\n",
            "httpx==0.28.1\n",
            "huggingface-hub==0.28.1\n",
            "humanize==4.11.0\n",
            "hyperframe==6.1.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.2.0\n",
            "id==1.5.0\n",
            "idna==3.10\n",
            "imageio==2.37.0\n",
            "imageio-ffmpeg==0.6.0\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.13.0\n",
            "imgaug==0.4.0\n",
            "immutabledict==4.2.1\n",
            "importlib_metadata==8.6.1\n",
            "importlib_resources==6.5.2\n",
            "imutils==0.5.4\n",
            "in-toto-attestation==0.9.3\n",
            "inflect==7.5.0\n",
            "iniconfig==2.0.0\n",
            "intel-cmplr-lib-ur==2025.0.4\n",
            "intel-openmp==2025.0.4\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==6.17.1\n",
            "ipyleaflet==0.19.2\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jax==0.4.33\n",
            "jax-cuda12-pjrt==0.4.33\n",
            "jax-cuda12-plugin==0.4.33\n",
            "jaxlib==0.4.33\n",
            "jeepney==0.7.1\n",
            "jellyfish==1.1.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.5\n",
            "jiter==0.8.2\n",
            "joblib==1.4.2\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.0.1\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.23.0\n",
            "jsonschema-specifications==2024.10.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-leaflet==0.19.2\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.2\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.13\n",
            "kaggle==1.6.17\n",
            "kagglehub==0.3.7\n",
            "keras==3.8.0\n",
            "keras-hub==0.18.1\n",
            "keras-nlp==0.18.1\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.8\n",
            "langchain==0.3.18\n",
            "langchain-core==0.3.35\n",
            "langchain-text-splitters==0.3.6\n",
            "langcodes==3.5.0\n",
            "langsmith==0.3.8\n",
            "language_data==1.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl\n",
            "libkvikio-cu12==24.12.1\n",
            "librosa==0.10.2.post1\n",
            "lightgbm==4.5.0\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.44.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==5.3.1\n",
            "marisa-trie==1.2.1\n",
            "Markdown==3.7\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==3.0.2\n",
            "matplotlib==3.10.0\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.1\n",
            "mdit-py-plugins==0.4.2\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==3.1.1\n",
            "mizani==0.13.1\n",
            "mkl==2025.0.1\n",
            "ml-dtypes==0.4.1\n",
            "mlxtend==0.23.4\n",
            "model-signing==0.2.0\n",
            "more-itertools==10.6.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.0\n",
            "multidict==6.1.0\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.12\n",
            "music21==9.3.0\n",
            "namex==0.0.8\n",
            "narwhals==1.26.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.2.0\n",
            "nbclient==0.10.2\n",
            "nbconvert==7.16.6\n",
            "nbformat==5.10.4\n",
            "ndindex==1.9.2\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.4.2\n",
            "nibabel==5.3.2\n",
            "nltk==3.9.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.61.0\n",
            "numba-cuda==0.0.17.1\n",
            "numexpr==2.10.2\n",
            "numpy==1.26.4\n",
            "nvidia-cublas-cu12==12.5.3.2\n",
            "nvidia-cuda-cupti-cu12==12.5.82\n",
            "nvidia-cuda-nvcc-cu12==12.5.82\n",
            "nvidia-cuda-nvrtc-cu12==12.5.82\n",
            "nvidia-cuda-runtime-cu12==12.5.82\n",
            "nvidia-cudnn-cu12==9.3.0.75\n",
            "nvidia-cufft-cu12==11.2.3.61\n",
            "nvidia-curand-cu12==10.3.6.82\n",
            "nvidia-cusolver-cu12==11.6.3.83\n",
            "nvidia-cusparse-cu12==12.5.1.3\n",
            "nvidia-nccl-cu12==2.21.5\n",
            "nvidia-nvcomp-cu12==4.1.0.6\n",
            "nvidia-nvjitlink-cu12==12.5.82\n",
            "nvidia-nvtx-cu12==12.4.127\n",
            "nvtx==0.2.10\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.12.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "openai==1.61.1\n",
            "opencv-contrib-python==4.11.0.86\n",
            "opencv-python==4.11.0.86\n",
            "opencv-python-headless==4.11.0.86\n",
            "openpyxl==3.1.5\n",
            "opentelemetry-api==1.16.0\n",
            "opentelemetry-sdk==1.16.0\n",
            "opentelemetry-semantic-conventions==0.37b0\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.4\n",
            "optree==0.14.0\n",
            "orbax-checkpoint==0.6.4\n",
            "orjson==3.10.15\n",
            "osqp==0.6.7.post3\n",
            "packaging==24.2\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.26.1\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.6.0\n",
            "param==2.2.0\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "pathlib==1.0.1\n",
            "patsy==1.0.1\n",
            "peewee==3.17.9\n",
            "peft==0.14.0\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.1.0\n",
            "platformdirs==4.3.6\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.5\n",
            "pluggy==1.5.0\n",
            "ply==3.11\n",
            "polars==1.9.0\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.9\n",
            "prettytable==3.14.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.21.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.50\n",
            "propcache==0.2.1\n",
            "prophet==1.1.6\n",
            "proto-plus==1.26.0\n",
            "protobuf==4.25.6\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.10\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==17.0.0\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.1\n",
            "pycocotools==2.0.8\n",
            "pycparser==2.22\n",
            "pydantic==2.10.6\n",
            "pydantic_core==2.27.2\n",
            "pydata-google-auth==1.9.1\n",
            "pydot==3.0.4\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.21.3\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.17.0\n",
            "Pygments==2.18.0\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.10.1\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==24.12.0\n",
            "pylibraft-cu12==24.12.0\n",
            "pymc==5.20.1\n",
            "pymystem3==0.2.0\n",
            "pynvjitlink-cu12==0.5.0\n",
            "pyogrio==0.10.0\n",
            "Pyomo==6.8.2\n",
            "PyOpenGL==3.1.9\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.1\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.4\n",
            "pytensor==2.27.1\n",
            "pytest==8.3.4\n",
            "python-apt==0.0.0\n",
            "python-box==7.3.2\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-snappy==0.7.3\n",
            "python-utils==3.9.1\n",
            "pytz==2025.1\n",
            "pyviz_comms==3.0.4\n",
            "PyYAML==6.0.2\n",
            "pyzmq==24.0.1\n",
            "qdldl==0.1.7.post5\n",
            "ratelim==0.1.6\n",
            "referencing==0.36.2\n",
            "regex==2024.11.6\n",
            "requests==2.32.3\n",
            "requests-oauthlib==2.0.0\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rfc3161-client==0.1.2\n",
            "rfc8785==0.1.4\n",
            "rich==13.9.4\n",
            "rmm-cu12==24.12.1\n",
            "rpds-py==0.22.3\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.5.2\n",
            "scikit-image==0.25.1\n",
            "scikit-learn==1.6.1\n",
            "scipy==1.13.1\n",
            "scooby==0.10.0\n",
            "scs==3.2.7.post2\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.1\n",
            "securesystemslib==1.2.0\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==3.4.1\n",
            "sentencepiece==0.2.0\n",
            "sentry-sdk==2.21.0\n",
            "setproctitle==1.3.4\n",
            "shap==0.46.0\n",
            "shapely==2.0.7\n",
            "shellingham==1.5.4\n",
            "sigstore==3.6.1\n",
            "sigstore-protobuf-specs==0.3.2\n",
            "sigstore-rekor-types==0.0.18\n",
            "simple-parsing==0.1.7\n",
            "simsimd==6.2.1\n",
            "six==1.17.0\n",
            "sklearn-compat==0.1.3\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart-open==7.1.0\n",
            "smmap==5.0.2\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==2.2.0\n",
            "soundfile==0.13.1\n",
            "soupsieve==2.6\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.7.5\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "spanner-graph-notebook==1.1.1\n",
            "Sphinx==8.1.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.38\n",
            "sqlglot==25.6.1\n",
            "sqlparse==0.5.3\n",
            "srsly==2.5.1\n",
            "stanio==0.5.1\n",
            "statsmodels==0.14.4\n",
            "stringzilla==3.11.3\n",
            "sympy==1.13.1\n",
            "tables==3.10.2\n",
            "tabulate==0.9.0\n",
            "tbb==2022.0.0\n",
            "tcmlib==1.2.0\n",
            "tenacity==9.0.0\n",
            "tensorboard==2.18.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.18.0\n",
            "tensorflow-datasets==4.9.7\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.1\n",
            "tensorflow-metadata==1.16.1\n",
            "tensorflow-probability==0.25.0\n",
            "tensorflow-text==2.18.1\n",
            "tensorstore==0.1.71\n",
            "termcolor==2.5.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.19.0\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.18.0\n",
            "thinc==8.2.5\n",
            "threadpoolctl==3.5.0\n",
            "tifffile==2025.1.10\n",
            "timm==1.0.14\n",
            "tinycss2==1.4.0\n",
            "tokenizers==0.21.0\n",
            "toml==0.10.2\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "tornado==6.4.2\n",
            "tqdm==4.67.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.48.3\n",
            "treescope==0.1.8\n",
            "triton==3.1.0\n",
            "tuf==5.1.0\n",
            "tweepy==4.15.0\n",
            "typeguard==4.4.1\n",
            "typer==0.15.1\n",
            "types-pytz==2025.1.0.20250204\n",
            "types-setuptools==75.8.0.20250210\n",
            "typing_extensions==4.12.2\n",
            "tzdata==2025.1\n",
            "tzlocal==5.3\n",
            "uc-micro-py==1.0.3\n",
            "umf==0.9.1\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.3.0\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.19.6\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.11.1\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "websockets==14.2\n",
            "Werkzeug==3.1.3\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==1.17.2\n",
            "xarray==2025.1.2\n",
            "xarray-einstats==0.8.0\n",
            "xgboost==2.1.4\n",
            "xlrd==2.0.1\n",
            "xyzservices==2025.1.0\n",
            "yarl==1.18.3\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.52\n",
            "zipp==3.21.0\n",
            "zstandard==0.23.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip freeze\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veE0Iub4i-JQ"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "`str` has the `.split()` function which **splits** the string among any _whitespace_ producing a list of **tokens**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JYcaSBcIi-JQ",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "EXAMPLE = \"\"\"\n",
        "I love Jackson's movie! It's sweet, but with satirical humour. The dialogue is great and the adventure scenes are fun...\n",
        "It manages to be whimsical and romantic while laughing at the conventions of the fairytale genre.\n",
        "I would recommend it to just about anyone. I've seen in several times, and I'm always happy to see it again whenever\n",
        "I have a friend who hasn't seen it yet.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TqcGfyrni-JR",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b372eedf-aa3f-42e1-f9b8-9063592196f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: <class 'list'>\n",
            "Length: 67\n"
          ]
        }
      ],
      "source": [
        "tokens = EXAMPLE.split()\n",
        "\n",
        "print(f\"Type: {type(tokens)}\")\n",
        "print(f\"Length: {len(tokens)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "O0ioEnIEi-JR",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f691762-c41e-42a2-e446-6c54dd552263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', \"Jackson's\", 'movie!', \"It's\"] ['who', \"hasn't\", 'seen', 'it', 'yet.']\n"
          ]
        }
      ],
      "source": [
        "print(tokens[:5], tokens[-5:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Sc-I7Di-JS"
      },
      "source": [
        "### Remove punctuation\n",
        "- The module `string` has a predefined set `punctuation` which includes all punctuation marks.\n",
        "- The type `str` has the method `.replace()` which takes 2 arguments: the string to replace and the replacement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4EWtMnsuUZz"
      },
      "source": [
        "#### TASK 1.1\n",
        "Use the following to implement a loop to remove punctuation from `EXAMPLE`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fqgeZ17Ai-JS",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbbb21d6-7882-4050-a0dc-ed13ec7d9411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predefined Punctuation: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "\n",
            "I love Jacksons movie Its sweet but with satirical humour The dialogue is great and the adventure scenes are fun\n",
            "It manages to be whimsical and romantic while laughing at the conventions of the fairytale genre\n",
            "I would recommend it to just about anyone Ive seen in several times and Im always happy to see it again whenever\n",
            "I have a friend who hasnt seen it yet\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from string import punctuation\n",
        "\n",
        "print(f\"Predefined Punctuation: {punctuation}\")\n",
        "\n",
        "no_punctuation = EXAMPLE\n",
        "\n",
        "### IMPLEMENT YOUR SOLUTION HERE ####\n",
        "\n",
        "# no_punctuation = no_punctuation.translate(str.maketrans(\"\", \"\", punctuation))\n",
        "\n",
        "for char in punctuation:\n",
        "  no_punctuation = no_punctuation.replace(char, \" \")\n",
        "\n",
        "\n",
        "print(no_punctuation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eg3kbF2ni-JS",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53707e70-42d0-4ad9-db25-be09e5d69e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Punctuation:\n",
            " \n",
            "I love Jacksons movie Its sweet but with satirical humour The dialogue is great and the adventure scenes are fun\n",
            "It manages to be whimsical and romantic while laughing at the conventions of the fairytale genre\n",
            "I would recommend it to just about anyone Ive seen in several times and Im always happy to see it again whenever\n",
            "I have a friend who hasnt seen it yet\n",
            "\n",
            "Tokens:\n",
            " ['I', 'love', 'Jacksons', 'movie', 'Its'] ['who', 'hasnt', 'seen', 'it', 'yet']\n"
          ]
        }
      ],
      "source": [
        "print(\"No Punctuation:\\n\", no_punctuation)\n",
        "\n",
        "tokens = no_punctuation.split()\n",
        "\n",
        "print(\"Tokens:\\n\", tokens[:5], tokens[-5:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuRoXJ2Ui-JT"
      },
      "source": [
        "### Combine Negations / Normalize Apostrophe\n",
        "We could hardcode rules which things to normalize: \"it's\" â†’ \"it is\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GxOgUUJ-i-JU",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "normalize_rules = {\"n't\": \" not\", \"'m\": \" am\", \"'ve\": \" have\", \"'s\": \" is\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PqqQN3Nhi-JU",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "normalized = EXAMPLE\n",
        "\n",
        "for old, new in normalize_rules.items():\n",
        "    normalized = normalized.replace(old, new)\n",
        "\n",
        "for p in punctuation:\n",
        "    normalized = normalized.replace(p, \" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3YwyFoqGi-JU",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3de2358-be9d-448c-d58c-90c5e19396d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized:\n",
            " \n",
            "I love Jackson is movie  It is sweet  but with satirical humour  The dialogue is great and the adventure scenes are fun   \n",
            "It manages to be whimsical and romantic while laughing at the conventions of the fairytale genre \n",
            "I would recommend it to just about anyone  I have seen in several times  and I am always happy to see it again whenever\n",
            "I have a friend who has not seen it yet \n",
            "\n",
            "Tokens:\n",
            " ['I', 'love', 'Jackson', 'is', 'movie'] ['has', 'not', 'seen', 'it', 'yet']\n"
          ]
        }
      ],
      "source": [
        "print(\"Normalized:\\n\", normalized)\n",
        "\n",
        "tokens = normalized.split()\n",
        "\n",
        "print(\"Tokens:\\n\", tokens[:5], tokens[-5:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N086qsC4-O4Q"
      },
      "source": [
        "If we look at the output, we notice something:\n",
        "\n",
        "$\\texttt{['I', 'love', 'Jackson', }\\underbrace{\\texttt{'is'}}_{\\text{This is wrong!}} \\texttt{, 'movie']}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F1z86MEi-JU"
      },
      "source": [
        "There seems to be a problem with the `'s` replacement. It could also be the genitive case: we need to add the pronoun **it's** as well as the uppercase version **It's**. (OR convert the full text into lower case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wAPLrGm6i-JV",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "normalized = EXAMPLE\n",
        "\n",
        "normalize = {\n",
        "    \"It's\": \"It is\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"n't\": \" not\",\n",
        "    \"'m\": \" am\",\n",
        "    \"'ve\": \" have\",\n",
        "}\n",
        "\n",
        "for old, new in normalize.items():\n",
        "    normalized = normalized.replace(old, new)\n",
        "\n",
        "for p in punctuation:\n",
        "    normalized = normalized.replace(p, \" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2atTUeoUi-JV",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5db41d-ae97-494a-9c87-42ab4557355d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized:\n",
            " \n",
            "I love Jackson s movie  It is sweet  but with satirical humour  The dialogue is great and the adventure scenes are fun   \n",
            "It manages to be whimsical and romantic while laughing at the conventions of the fairytale genre \n",
            "I would recommend it to just about anyone  I have seen in several times  and I am always happy to see it again whenever\n",
            "I have a friend who has not seen it yet \n",
            "\n",
            "Tokens:\n",
            " ['I', 'love', 'Jackson', 's', 'movie'] ['has', 'not', 'seen', 'it', 'yet']\n"
          ]
        }
      ],
      "source": [
        "print(\"Normalized:\\n\", normalized)\n",
        "\n",
        "tokens = normalized.split()\n",
        "\n",
        "print(\"Tokens:\\n\", tokens[:5], tokens[-5:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhIO24-j_pJz"
      },
      "source": [
        "This is better than what we had previously:\n",
        "\n",
        "$\\texttt{['I', 'love', 'Jackson', }\\underbrace{\\texttt{'s'}}_{\\text{Used to be } \\texttt{'is'}} \\texttt{, 'movie']}$\n",
        "\n",
        "Depending on what we want to accomplish this is still not correct though. The **'s** is a possessive suffix, and by splitting the text like we do currently we lose this information. We can infer from the sentence that it used to be a possessive suffix, but it could also have been a typo that was present in the original text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwfrGbzci-JV"
      },
      "source": [
        "### Bag-of-Words\n",
        "\n",
        "Here, we use an *uncounted* version of bag-of-words: we create a `set` out of the tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6A47dadYi-JV",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c6014c-0d65-417d-9ccf-24aee25a1473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary count: 56\n",
            "Vocabulary:\n",
            " {'but', 'not', 'anyone', 's', 'humour', 'are', 'fun', 'always', 'conventions', 'satirical', 'just', 'the', 'great', 'I', 'movie', 'of', 'love', 'would', 'times', 'manages', 'has', 'have', 'be', 'with', 'dialogue', 'yet', 'sweet', 'The', 'about', 'see', 'It', 'am', 'laughing', 'again', 'friend', 'Jackson', 'at', 'who', 'it', 'while', 'whenever', 'happy', 'genre', 'whimsical', 'to', 'seen', 'fairytale', 'in', 'is', 'and', 'several', 'a', 'adventure', 'romantic', 'scenes', 'recommend'}\n"
          ]
        }
      ],
      "source": [
        "bow = set(tokens)\n",
        "\n",
        "print(f\"Vocabulary count: {len(bow)}\")\n",
        "\n",
        "print(\"Vocabulary:\\n\", bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sck5QVli-JV"
      },
      "source": [
        "### Stopword removal\n",
        "\n",
        "We see from the vocabulary, that many words **MIGHT** not influence a sentiment: pronouns, conjunctions, etc.\n",
        "\n",
        "We call these **stopwords** (because they *stop* the analysis)\n",
        "\n",
        "The module `nltk` has a predefined list of stopwords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Zof66FjlN7"
      },
      "source": [
        "We need to download this list first before we can use it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RwY3B4PzjeKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb891658-e028-4606-94f9-d6d935550fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qj3d1Afoi-JV",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38c496d-294f-497e-d344-c233b6a4ce86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary count: 30\n",
            "Vocabulary:\n",
            " {'anyone', 'humour', 'fun', 'always', 'conventions', 'satirical', 'great', 'movie', 'love', 'would', 'times', 'manages', 'dialogue', 'yet', 'sweet', 'see', 'laughing', 'friend', 'Jackson', 'whenever', 'happy', 'genre', 'whimsical', 'seen', 'fairytale', 'several', 'adventure', 'romantic', 'scenes', 'recommend'}\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "english_stopwords = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "tokens_without_stopwords = []\n",
        "\n",
        "for token in tokens:\n",
        "    if token.lower() not in english_stopwords:\n",
        "        tokens_without_stopwords.append(token)\n",
        "\n",
        "\n",
        "# BoW\n",
        "bow = set(tokens_without_stopwords)\n",
        "\n",
        "print(f\"Vocabulary count: {len(bow)}\")\n",
        "\n",
        "print(\"Vocabulary:\\n\", bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Tb2OU9Pni-JW",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "800e2a35-da93-4c58-e8a9-429931b4d6f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " \"he's\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " \"i've\",\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " \"we've\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "english_stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMH3rsBvi-JW"
      },
      "source": [
        "### Combine everything into functions\n",
        "\n",
        "To modularize the code and reuse it for any input, we have to create functions.\n",
        "Here, we create the following functions:\n",
        "    \n",
        "- Normalize according to predefined rules\n",
        "- Remove leftover punctuation\n",
        "- Remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cLhTnvdNi-JW",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Manual normalizing rules\n",
        "NORMALIZE_RULES = {\n",
        "    \"It's\": \"It is\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"n't\": \" not\",\n",
        "    \"'m\": \" am\",\n",
        "    \"'ve\": \" have\",\n",
        "    \"'re\": \" are\",\n",
        "}\n",
        "\n",
        "# Punctuation from string module (as set => faster)\n",
        "PUNCTUATION = set(punctuation)\n",
        "\n",
        "# Stopwords from NLTK (as set => faster)\n",
        "STOPWORDS = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kUH7QbJ0i-JW",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def normalize(text):\n",
        "    for old, new in NORMALIZE_RULES.items():\n",
        "        text = text.replace(old, new)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8CaTXxG5i-JW",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "    for p in PUNCTUATION:\n",
        "        text = text.replace(p, \" \")\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "F-AJ0X5wi-JW",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(tokens):\n",
        "    clean = []\n",
        "    for token in tokens:\n",
        "        if token.lower() not in STOPWORDS:\n",
        "            clean.append(token)\n",
        "    return clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1BzgOvTuUZ5"
      },
      "source": [
        "#### TASK 1.2\n",
        "Write a function for tokenization utilizing the above defined functions. The tokenization function should do the following:\n",
        "1. Normalize the text\n",
        "2. Remove punctuation from the text\n",
        "3. split the text in tokens\n",
        "4. Remove the stopwords from the tokens\n",
        "5. Apply Bag-of-Words and return bow as set of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fyClEpBxuUZ5"
      },
      "outputs": [],
      "source": [
        "def tokenization(text):\n",
        "    bow = text\n",
        "    ### IMPLEMENT YOUR SOLUTION HERE ###\n",
        "    # 1. Normalize\n",
        "    bow = normalize(bow)\n",
        "    # 2. Remove Punctuation\n",
        "    bow = remove_punctuation(bow)\n",
        "    # 3. Tokenize\n",
        "    bow = bow.split()\n",
        "    # 4. Remove Stopwords\n",
        "    bow = remove_stopwords(bow)\n",
        "    # 5. Apply Bag-of-Words (set of tokens)\n",
        "    bow = set(bow)\n",
        "\n",
        "    return bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "6TqADDYSi-JX",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08f793d-a1b4-4d19-92a3-651c301c3048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : 'This is a great movie.'\n",
            "Tokens: {'movie', 'great'}\n"
          ]
        }
      ],
      "source": [
        "example = \"This is a great movie.\"\n",
        "\n",
        "print(f\"Input : '{example}'\")\n",
        "print(f\"Tokens: {tokenization(example)}\")\n",
        "\n",
        "# This should output the following:\n",
        "# Input : 'This is a great movie.'\n",
        "# Tokens: {'great', 'movie'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "q0GrnSFqi-JX",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9509681b-11dd-44f5-d29e-79f1e99ea067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : 'This is a bad movie.'\n",
            "Tokens: {'movie', 'bad'}\n"
          ]
        }
      ],
      "source": [
        "example = \"This is a bad movie.\"\n",
        "\n",
        "print(f\"Input : '{example}'\")\n",
        "print(f\"Tokens: {tokenization(example)}\")\n",
        "\n",
        "# This should output the following:\n",
        "# Input : 'This is a bad movie.'\n",
        "# Tokens: {'bad', 'movie'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "KZ5PP7Dyi-JX",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c6f9b6-430f-40b8-db8b-8140a63ced17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : 'I'm enjoying this movie so much, you will, too.'\n",
            "Tokens: {'movie', 'enjoying', 'much'}\n"
          ]
        }
      ],
      "source": [
        "example = \"I'm enjoying this movie so much, you will, too.\"\n",
        "\n",
        "print(f\"Input : '{example}'\")\n",
        "print(f\"Tokens: {tokenization(example)}\")\n",
        "\n",
        "# This should output the following:\n",
        "# Input : 'I'm enjoying this movie so much, you will, too.'\n",
        "# Tokens: {'much', 'enjoying', 'movie'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9qvxBoEi-JX"
      },
      "source": [
        "## Basic Classifier based on hardcoded rules\n",
        "\n",
        "We can define a list of important words for each sentiment (_good_ or _bad_) and then count how often each appears in the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "aNkebYVIi-JY",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "POSITIVE_SENTIMENT = set([\"good\", \"best\", \"great\", \"like\", \"enjoy\", \"love\"])\n",
        "\n",
        "NEGATIVE_SENTIMENT = set([\"bad\", \"worst\", \"unlikable\", \"hate\", \"trash\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGFkrFMFi-JY"
      },
      "source": [
        "Now, we need a functions that counts how often each word appears, compares the two approaches, and outputs the class with the most appearances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "us_IZhWRi-JY",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def classify(text):\n",
        "    bow = tokenization(text)\n",
        "\n",
        "    positive_count, negative_count = 0, 0\n",
        "\n",
        "    for word in bow:\n",
        "        if word in POSITIVE_SENTIMENT:\n",
        "            positive_count += 1\n",
        "        elif word in NEGATIVE_SENTIMENT:\n",
        "            negative_count += 1\n",
        "\n",
        "    if positive_count > negative_count:\n",
        "        return \"POSITIVE\"\n",
        "    else:\n",
        "        return \"NEGATIVE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "gKXdBas5i-JY",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "653d31c0-3e82-4c93-c75f-46cb42cf46ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "classify(\"This is the worst movie of all time.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "_ap962Uci-JY",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1f4e1d20-6089-46a7-d5a5-b3ab9b5e5c9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "classify(\"This is a trash movie. I hate that I love it so much.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "XnAtKm8-i-JY",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4f8c1adc-5f09-447f-9144-e4389fe461ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "classify(\"Other people said that I would like this movie. I don't.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "SzynNfY4i-JY",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dea2d8d7-934d-4b99-af04-d5afef4bf13a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'POSITIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "classify(EXAMPLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "EJEgcB5Hi-JY",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dabcb8f9-f4dd-4157-88a3-d5d8801c1933"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NEGATIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "classify(\"I LOVE this movie.\")  # should lowercase everything, right?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHnb8dK5i-JZ"
      },
      "source": [
        "<p style=\"color: #749CFF; background: #ccffff; font-size: xx-large\">\n",
        "    <br />\n",
        "    <strong>\n",
        "        Now, we have our first Artificial Intelligence.\n",
        "    </strong>\n",
        "    <br /><br />\n",
        "</p>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "HSG_NLP_EDU",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}