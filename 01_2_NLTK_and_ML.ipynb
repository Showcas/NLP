{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Showcas/NLP/blob/main/01_2_NLTK_and_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UroXYasai_LV"
      },
      "source": [
        "# Natural Language Processing with Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPuvDbXgi_LY"
      },
      "source": [
        "After understanding the process:\n",
        "\n",
        "**Preprocessing**:\n",
        "\n",
        "- Tokenization\n",
        "- Normalization\n",
        "- Punctuation\n",
        "- ...\n",
        "\n",
        "And after **Feature Extraction**:\n",
        "\n",
        "- Bag-of-Words\n",
        "- ...\n",
        "\n",
        "\n",
        "We will **TRAIN** a classifier with the _features_ **and** the _class_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLZPkCyDi_LZ"
      },
      "source": [
        "# NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JfmfLsbVi_La",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "925MewGDi_Lc"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "But first, we need a dataset.\n",
        "\n",
        "We already know `nltk`. There are a few corpora already included, so let's use them for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bzDF3nqAi_Lc",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Import the movie_reviews submodule which provides Movie Reviews\n",
        "from nltk.corpus import movie_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KzYdCJE0EtDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4184288-105b-402e-f638-1a93db9c1e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# just like with the stopwords, we need to download this corpus\n",
        "import nltk\n",
        "nltk.download('movie_reviews')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_Cyl1ewLi_Ld",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e0fe85-2745-488c-cdc2-f0a7309ee39a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neg', 'pos']\n"
          ]
        }
      ],
      "source": [
        "# Two possible classes:\n",
        "print(movie_reviews.categories())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u5PNEp1HMppD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e94552c-695c-4741-cc20-6c105fef322a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg/cv000_29416.txt',\n",
              " 'neg/cv001_19502.txt',\n",
              " 'neg/cv002_17424.txt',\n",
              " 'neg/cv003_12683.txt',\n",
              " 'neg/cv004_12641.txt',\n",
              " 'neg/cv005_29357.txt',\n",
              " 'neg/cv006_17022.txt',\n",
              " 'neg/cv007_4992.txt',\n",
              " 'neg/cv008_29326.txt',\n",
              " 'neg/cv009_29417.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# getting all fileids for a class\n",
        "movie_reviews.fileids('neg')[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QBscDD48M1ch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "06c9ea05-50c3-4360-fb91-31aae6cf192d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'plot : two teen couples go to a church party , drink and then drive . \\nthey get into an accident . \\none of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \\nwhat\\'s the deal ? \\nwatch the movie and \" sorta \" find out . . . \\ncritique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \\nwhich is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn\\'t snag this one correctly . \\nthey seem to have taken this pretty neat concept , but executed it terribly . \\nso what are the problems with the movie ? \\nwell , its main problem is that it\\'s simply too jumbled . \\nit starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what\\'s going on . \\nthere are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . \\nnow i personally don\\'t mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film\\'s biggest problem . \\nit\\'s obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . \\nand do they make things entertaining , thrilling or even engaging , in the meantime ? \\nnot really . \\nthe sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn\\'t the make the film all that more entertaining . \\ni guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . \\ni mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! \\nokay , we get it . . . there \\nare people chasing her and we don\\'t know who they are . \\ndo we really need to see it over and over again ? \\nhow about giving us different scenes offering further insight into all of the strangeness going down in the movie ? \\napparently , the studio took this film away from its director and chopped it up themselves , and it shows . \\nthere might\\'ve been a pretty decent teen mind-fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . \\nthe actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . \\nbut my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character\\'s unraveling . \\noverall , the film doesn\\'t stick because it doesn\\'t entertain , it\\'s confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . \\noh , and by the way , this is not a horror or teen slasher flick . . . it\\'s \\njust packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . \\nit also wrapped production two years ago and has been sitting on the shelves ever since . \\nwhatever . . . skip \\nit ! \\nwhere\\'s joblo coming from ? \\na nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# getting raw review text\n",
        "movie_reviews.raw('neg/cv000_29416.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "id6nXny_NgRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575dc64c-853a-47ff-d00d-78b6e264906a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# getting review text, already split for us\n",
        "movie_reviews.words('neg/cv000_29416.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0qdXILPmi_Ld",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Read all 'neg' reviews\n",
        "neg_files = movie_reviews.fileids(categories=[\"neg\"])\n",
        "\n",
        "neg_reviews = [movie_reviews.raw(fileids=fileid) for fileid in neg_files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-jJHjWeBi_Lf",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Same for 'pos' reviews\n",
        "pos_files = movie_reviews.fileids(categories=[\"pos\"])\n",
        "\n",
        "pos_reviews = [movie_reviews.raw(fileids=fileid) for fileid in pos_files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IQVusp9ji_Lf",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9091c63b-931d-40cd-cd0b-0c6cd46e9805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#neg: 1000\n",
            "#pos: 1000\n"
          ]
        }
      ],
      "source": [
        "# Check sizes:\n",
        "print(f\"#neg: {len(neg_reviews)}\")\n",
        "print(f\"#pos: {len(pos_reviews)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "AE8fp7t9i_Lg",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88d09c9-b945-4c94-dbf6-8608ce17f8c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neg:\n",
            " a pseudo-intellectual film about the pseudo-intellectual world of art magazines , high art is as wasted as its drug-addled protagonists . \n",
            "in the only notable part of the movie , ally sheedy and radha mitchell deliver nice performances in the two leading roles , not that lisa cholodenko's script or direction makes you care much about either character . \n",
            "living in a world of heroin induced highs , they float along until they fall in love with each other . \n",
            "this uninviting picture , full of pretentious minor characters , has a receptionist that reads dostoevski and a woman in the restroom line who is a certified genius , having recently been awarded a prestigious mcarthur grant . \n",
            "24-year-old syd ( radha mitchell ) , who has a rather bland , live-in boyfriend , was just promoted to assistant editor at the artistic photography magazine \" frame . \" \n",
            "although the receptionist is impressed , syd is mainly a gofer for her boss until she meets famous photographer lucy berliner ( ally sheedy ) . \n",
            "for her to do photos for \" frame , \" lucy demands that syd be promoted to editor and assigned to her since lucy fancies her . \n",
            "lucy lives with her current lover , a washed up german actress named greta , played with a frequently indecipherable series of mumbles by patricia clarkson . \n",
            "the two of them and their friends wile away their time snorting and shooting up dope , usually heroin . \n",
            "this does not happen in a single episode , but becomes more commonplace than sleeping in the picture . \n",
            "syd , who lives in the apartment below them , joins in on the fun and becomes a member of the zombie club . \n",
            "lucy seems pretty happy with her life of drugs , which apparently is funded by her mother . \n",
            "lucy quit working professionally 10 years ago since she thought she was being \" pigeonholed , \" and , since her mother has money , we can only assume that that's how lucy supports her habit and procures her living expenses . \n",
            "a typical scene has the editors arguing about whether a potential photographer's work is transcendental or merely classical . \n",
            "that no one has a clue as to the dogma they are spouting becomes obvious but not particularly funny . \n",
            " \" your work has a cultural currency that is important now , \" is the artist-speak that the frame's manager uses to convince lucy to show her pictures in the magazine . \n",
            "when the big scene comes in which lucy puts the moves on syd , her idea of a romantic line is , \" i want to get high with you . \" \n",
            "in lucy's world , sex and drugs come hand-in-hand . \n",
            "and the movie , except for the obligatory scene of someone almost overdosing , shows drug usage as being a hip and natural part of the art scene . \n",
            "this vacuous picture throws in a standard downer ending in an attempt to manipulate our emotions . \n",
            "in another movie , it might have worked , but in this one the reaction is likely to be decidedly muted . \n",
            "high art runs 1 : 36 . \n",
            "it is rated r for explicit sex , pervasive drug use and language and is not appropriate for those younger than college age . \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Neg Example:\n",
        "print(f\"Neg:\\n {neg_reviews[42]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sYsZx8Cji_Lg",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c33d22d-ad33-4051-90f8-c7d6f1da990b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pos:\n",
            " you've got mail works alot better than it deserves to . \n",
            "in order to make the film a success , all they had to do was cast two extremely popular and attractive stars , have them share the screen for about two hours and then collect the profits . \n",
            "no real acting was involved and there is not an original or inventive bone in it's body ( it's basically a complete re-shoot of the shop around the corner , only adding a few modern twists ) . \n",
            "essentially , it goes against and defies all concepts of good contemporary filmmaking . \n",
            "it's overly sentimental and at times terribly mushy , not to mention very manipulative . \n",
            "but oh , how enjoyable that manipulation is . \n",
            "but there must be something other than the casting and manipulation that makes the movie work as well as it does , because i absolutely hated the previous ryan/hanks teaming , sleepless in seattle . \n",
            "it couldn't have been the directing , because both films were helmed by the same woman . \n",
            "i haven't quite yet figured out what i liked so much about you've got mail , but then again , is that really important ? \n",
            "if you like something so much , why even question it ? \n",
            "again , the storyline is as cliched as they come . \n",
            "tom hanks plays joe fox , the insanely likeable owner of a discount book chain and meg ryan plays kathleen kelley , the even more insanely likeable proprietor of a family-run children's book shop called , in a nice homage , the shop around the corner . \n",
            "fox and kelley soon become bitter rivals because the new fox books store is opening up right across the block from the small business . \n",
            "little do they know , they are already in love with each other over the internet , only neither party knows the other person's true identity . \n",
            "the rest of the story isn't important because all it does is serve as a mere backdrop for the two stars to share the screen . \n",
            "sure , there are some mildly interesting subplots , but they all fail in comparison to the utter cuteness of the main relationship . \n",
            "all of this , of course , leads up to the predictable climax . \n",
            "but as foreseeable as the ending is , it's so damn cute and well-done that i doubt any movie in the entire year contains a scene the evokes as much pure joy as this part does . \n",
            "when ryan discovers the true identity of her online love , i was filled with such , for lack of a better word , happiness that for the first time all year , i actually left the theater smiling . \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pos Example:\n",
        "print(f\"Pos:\\n {pos_reviews[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9sfZKvQi_Lh"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "We see from the example, that everything is lowercase anyway, so we don't have to deal with this.\n",
        "\n",
        "Also, interpunctuation is divided from its word: No normalization needed.\n",
        "We can see this for example here:\n",
        "\n",
        "> ( it's basically a complete re-shoot of the shop around the corner , only adding a few modern twists ) .\n",
        "\n",
        "There are spaces before and after the brackets, the comma and the period at the end.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "So, we do the following:\n",
        "\n",
        "1. Split on whitespaces\n",
        "2. Remove stopwords and interpunctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "LSVtvMqFi_Lh",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0cfb3ce-9e10-4e3a-b61f-562efa18056f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'Demo', 'Text', 'for', 'NLP', 'using', 'NLTK.', 'Full', 'form', 'of', 'NLTK', 'is', 'Natural', 'Language', 'Toolkit']\n"
          ]
        }
      ],
      "source": [
        "example = \"This is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
        "\n",
        "# List of all tokens:\n",
        "print(example.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "5lblt7c2E3bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783d526a-e5db-40f4-edb7-c496d99d9648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# for the tokenization, we will need to download the tokenizer first\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "f_zz_AeHi_Lh",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a6ef0e-f164-4a4d-924d-7113946a29a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'Demo', 'Text', 'for', 'NLP', 'using', 'NLTK', '.', 'Full', 'form', 'of', 'NLTK', 'is', 'Natural', 'Language', 'Toolkit']\n"
          ]
        }
      ],
      "source": [
        "example = \"This is a Demo Text for NLP using NLTK. Full form of NLTK is Natural Language Toolkit\"\n",
        "\n",
        "# Now with nltk.word_tokenize:\n",
        "print(nltk.word_tokenize(example))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "649asfNHFAeu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d84883-f989-4a6d-9b1c-6fcad5e586a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "bybNpt_Ki_Lh",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# First, we define the constants\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Use stopwords from NLTK, create a set for faster comparison\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Add punctuation to stopword set (.union() for UNION)\n",
        "STOPWORDS = STOPWORDS.union(set(punctuation))\n",
        "\n",
        "# Add custom stopwords that we know appear in the text\n",
        "STOPWORDS.add('--')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "UhFebtK5i_Li",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define a function for easier access.\n",
        "def tokenization(text):\n",
        "  # Return a list of the \"important\" tokens.\n",
        "  # This is a list comprehension.\n",
        "  #   1. text.split() is called\n",
        "  #   2. Similar to a for loop, the result from 1. is iterated\n",
        "  #   3. The token is added to the final list if its not in the stopword set\n",
        "  #   4. The list is returned\n",
        "  return [token for token in nltk.word_tokenize(text) if token not in STOPWORDS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "WnYrw7osh3Jj"
      },
      "outputs": [],
      "source": [
        "# this function is equivalent to the one above\n",
        "# it's easier to read due to not using a list comprehension\n",
        "def tokenization_verbose(text):\n",
        "  tokenized = nltk.word_tokenize(text)\n",
        "  out = []\n",
        "  for token in tokenized:\n",
        "    if token not in STOPWORDS:\n",
        "      out.append(token)\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "sN7Y6lWOi_Li",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9190a4f7-a585-4eb0-b9cb-cf50e98900ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['plot',\n",
              " 'two',\n",
              " 'teen',\n",
              " 'couples',\n",
              " 'go',\n",
              " 'church',\n",
              " 'party',\n",
              " 'drink',\n",
              " 'drive',\n",
              " 'get']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Example:\n",
        "tokenization(neg_reviews[0])[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "8hA0Aociiqrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ba6c91-bdb1-4995-cac6-38e237779d00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "tokenization(neg_reviews[0]) == tokenization_verbose(neg_reviews[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1XYWcHPi_Li"
      },
      "source": [
        "## Feature Extraction\n",
        "\n",
        "We use a simple Bag-of-Words approach here. So, first we need to create a full vocabulary, so that we can say that each word is a feature. We do that by reading the _full_ corpus (\n",
        "    <strong style='color: #FF6666'>Don't do this later; this is just an example!</strong>\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Laav-E3wi_Li",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62f04a8-08b0-4cfb-cfab-043c54db8bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Vocabulary: 46_289\n"
          ]
        }
      ],
      "source": [
        "vocabulary = set(\n",
        "    token for text in neg_reviews + pos_reviews for token in tokenization(text)\n",
        ")\n",
        "\n",
        "print(f\"Size of Vocabulary: {len(vocabulary):_}\")\n",
        "\n",
        "# We need the vocabulary as a list\n",
        "vocabulary = sorted(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A_mbcclfi_Lj",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93212f8c-da91-4d01-8fe5-726f89ee54e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'donald'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "vocabulary[12345]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIyx2aRAi_Lj"
      },
      "source": [
        "Our final list of features **for each** text will be list of 46'289 items: It will be a list of `True` and `False` values, where `True` indicates that the word in the vocabulary list at this position is inside the text.\n",
        "\n",
        "Example: `vocabulary[12345]` is the word `\"donald\"`.\n",
        "If now a text contains this exact word `\"donald\"`, its own feature list will be `True` *at position* `12345`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKvqf2rXi_Lj"
      },
      "source": [
        "```python\n",
        "neg_feature_list = [\n",
        "    [\n",
        "        vocab_item in tokenization(text)\n",
        "        for vocab_item in vocabulary\n",
        "    ]\n",
        "    for text in neg_reviews\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4flXVqLXi_Lk"
      },
      "source": [
        "<strong style='color: #FF6666'>Abort! This takes massively too long and too much storage.</strong>\n",
        "\n",
        "It has to store 50'000 boolean values for each of the 2'000 texts. This is too much.\n",
        "\n",
        "Is there a strategy to reduce the number of features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUSCLv2Oi_Lk"
      },
      "source": [
        "We could use just 100 words instead of _all of them_. But which ones?\n",
        "\n",
        "- Random ones (does this make sense?)\n",
        "- 100 most common words\n",
        "- ???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGrojS95i_Lk"
      },
      "source": [
        "Let's focus on **2**. But how do we count the number of appearances?\n",
        "\n",
        "We can do this ourselves with a good-oldfashioned dictionary. But there is a module for that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "OjOOlR6ri_Lk",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24abd7d1-f7b2-4f95-a2e0-c175cb9d1107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example:\n",
            " Counter({'a': 3, 'b': 2, 'c': 1, 'd': 1})\n"
          ]
        }
      ],
      "source": [
        "# Counter will count that what we put in:\n",
        "from collections import Counter\n",
        "\n",
        "print(\"Example:\\n\", Counter([\"a\", \"b\", \"a\", \"c\", \"a\", \"b\", \"d\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJKv6hs2EBhH"
      },
      "source": [
        "A `Counter` is similar to a dictionary: `c['a']` will return the number of appearances of the string `'a'`. Other than a dictionary, it can return 0 if there is no appearance.\n",
        "\n",
        "But wait, there's more:\n",
        "\n",
        "`.most_common(num)`: Returns the top-`num` most occuring tokens as a list of tuples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k2HNjSxEBhH"
      },
      "source": [
        "#### TASK 1.3\n",
        "Count all tokens in all of the texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "kn51r6QhEBhI"
      },
      "outputs": [],
      "source": [
        "### IMPLEMENT YOUR SOLUTION HERE ###\n",
        "\n",
        "all_reviews = list(map(movie_reviews.raw, movie_reviews.fileids()))\n",
        "\n",
        "full_count = Counter(\n",
        "    word for review in all_reviews for word in tokenization(review)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "rt81RdHHEBhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec76f5b-319d-4b89-b88e-30764a2e4331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(\"'s\", 18128), ('``', 17625), ('film', 9443), (\"n't\", 6217), ('movie', 5671), ('one', 5582), ('like', 3547), ('even', 2556), ('good', 2316), ('time', 2282)]\n"
          ]
        }
      ],
      "source": [
        "# Test the solution and let's see the most common word/token:\n",
        "print(full_count.most_common(10))\n",
        "\n",
        "# The output should be:\n",
        "# [(\"'s\", 18128), ('``', 17625), ('film', 9443), (\"n't\", 6217), ('movie', 5671), ('one', 5582), ('like', 3547), ('even', 2556), ('good', 2316), ('time', 2282)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "8im09xvui_Ll",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f47685-2a24-4dca-9924-261bf86b96a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'re\", \"'s\", \"'ve\", '``', 'action', 'actually', 'almost', 'also', 'although', 'another', 'around', 'audience', 'back', 'bad', 'best', 'better', 'big', 'cast', 'character', 'characters', 'come', 'comedy', 'could', 'director', 'end', 'enough', 'even', 'ever', 'every', 'fact', 'film', 'films', 'find', 'first', 'funny', 'get', 'gets', 'go', 'going', 'good', 'great', 'however', 'john', 'know', 'last', 'life', 'like', 'little', 'long', 'look']\n"
          ]
        }
      ],
      "source": [
        "# It's a tuple! [0] is the token itself, [1] is the number of appearances\n",
        "\n",
        "# Now, we can create the vocabulary out of the 100 most occuring words:\n",
        "\n",
        "vocabulary = sorted(token for token, _ in full_count.most_common(100))\n",
        "\n",
        "print(vocabulary[:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXBspI9wi_Ll"
      },
      "source": [
        "The **Feature Extraction** is now finished. But the classifier needs a combination of **FEATURES** and the **CLASS**.\n",
        "\n",
        "We call that the _training data_.\n",
        "\n",
        "Usually a list of tuples: (features, class), (features, class), ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2QCch7Ei_Ll"
      },
      "source": [
        "## Classifier\n",
        "\n",
        "Next, we need a classifier that can work with our data.\n",
        "\n",
        "We will see `NLTK`'s version and later the one from `scikit-learn`. Unfortunately, it needs a specific input format.\n",
        "The features per text must be a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "7FptaF2qi_Lm",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def extract_features(text_tokens):\n",
        "    feature = {}\n",
        "    for word in vocabulary:\n",
        "        feature[f\"contains({word})\"] = word in text_tokens\n",
        "    return feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "O-ARbD_hi_Lm",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "all_neg_features = [extract_features(tokenization(text)) for text in neg_reviews]\n",
        "\n",
        "all_pos_features = [extract_features(tokenization(text)) for text in pos_reviews]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "lZR1Tqp-i_Lm",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b50d7c-e2c9-4b9e-f42e-2acf982a7d21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"contains('re)\": False,\n",
              " \"contains('s)\": True,\n",
              " \"contains('ve)\": True,\n",
              " 'contains(``)': True,\n",
              " 'contains(action)': False,\n",
              " 'contains(actually)': True,\n",
              " 'contains(almost)': False,\n",
              " 'contains(also)': True,\n",
              " 'contains(although)': True,\n",
              " 'contains(another)': False,\n",
              " 'contains(around)': False,\n",
              " 'contains(audience)': True,\n",
              " 'contains(back)': True,\n",
              " 'contains(bad)': True,\n",
              " 'contains(best)': False,\n",
              " 'contains(better)': False,\n",
              " 'contains(big)': True,\n",
              " 'contains(cast)': False,\n",
              " 'contains(character)': True,\n",
              " 'contains(characters)': True,\n",
              " 'contains(come)': False,\n",
              " 'contains(comedy)': False,\n",
              " 'contains(could)': False,\n",
              " 'contains(director)': True,\n",
              " 'contains(end)': False,\n",
              " 'contains(enough)': False,\n",
              " 'contains(even)': True,\n",
              " 'contains(ever)': True,\n",
              " 'contains(every)': True,\n",
              " 'contains(fact)': False,\n",
              " 'contains(film)': True,\n",
              " 'contains(films)': True,\n",
              " 'contains(find)': True,\n",
              " 'contains(first)': False,\n",
              " 'contains(funny)': False,\n",
              " 'contains(get)': True,\n",
              " 'contains(gets)': False,\n",
              " 'contains(go)': True,\n",
              " 'contains(going)': True,\n",
              " 'contains(good)': True,\n",
              " 'contains(great)': False,\n",
              " 'contains(however)': False,\n",
              " 'contains(john)': False,\n",
              " 'contains(know)': True,\n",
              " 'contains(last)': False,\n",
              " 'contains(life)': True,\n",
              " 'contains(like)': True,\n",
              " 'contains(little)': True,\n",
              " 'contains(long)': False,\n",
              " 'contains(look)': True,\n",
              " 'contains(love)': False,\n",
              " 'contains(made)': False,\n",
              " 'contains(make)': True,\n",
              " 'contains(makes)': True,\n",
              " 'contains(man)': False,\n",
              " 'contains(many)': False,\n",
              " 'contains(may)': False,\n",
              " 'contains(movie)': True,\n",
              " 'contains(movies)': True,\n",
              " 'contains(much)': False,\n",
              " \"contains(n't)\": True,\n",
              " 'contains(never)': False,\n",
              " 'contains(new)': True,\n",
              " 'contains(nothing)': False,\n",
              " 'contains(one)': True,\n",
              " 'contains(people)': True,\n",
              " 'contains(performance)': False,\n",
              " 'contains(played)': False,\n",
              " 'contains(plays)': False,\n",
              " 'contains(plot)': True,\n",
              " 'contains(real)': False,\n",
              " 'contains(really)': True,\n",
              " 'contains(right)': False,\n",
              " 'contains(role)': False,\n",
              " 'contains(say)': False,\n",
              " 'contains(scene)': False,\n",
              " 'contains(scenes)': True,\n",
              " 'contains(script)': False,\n",
              " 'contains(see)': True,\n",
              " 'contains(seems)': True,\n",
              " 'contains(seen)': False,\n",
              " 'contains(since)': True,\n",
              " 'contains(something)': False,\n",
              " 'contains(still)': True,\n",
              " 'contains(story)': False,\n",
              " 'contains(take)': False,\n",
              " 'contains(thing)': False,\n",
              " 'contains(things)': True,\n",
              " 'contains(think)': False,\n",
              " 'contains(though)': False,\n",
              " 'contains(time)': False,\n",
              " 'contains(two)': True,\n",
              " 'contains(us)': True,\n",
              " 'contains(way)': True,\n",
              " 'contains(well)': True,\n",
              " 'contains(work)': False,\n",
              " 'contains(world)': True,\n",
              " 'contains(would)': True,\n",
              " 'contains(years)': True,\n",
              " 'contains(young)': False}"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "# Example:\n",
        "all_neg_features[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "aJphu1R6i_Ln",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# To train, we need to attach the LABEL to each feature set:\n",
        "\n",
        "training_data = []  # final list to contain training data tuples\n",
        "\n",
        "# First, we add the features for the 'neg' class:\n",
        "training_data.extend([(feature, \"neg\") for feature in all_neg_features])\n",
        "\n",
        "# Then, we add the features for the 'pos' class:\n",
        "training_data.extend([(feature, \"pos\") for feature in all_pos_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ljWN0C0Ii_Ln",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a3fdb2-c892-4df4-cb56-bd7d87602dfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({\"contains('re)\": False,\n",
              "  \"contains('s)\": True,\n",
              "  \"contains('ve)\": True,\n",
              "  'contains(``)': True,\n",
              "  'contains(action)': False,\n",
              "  'contains(actually)': True,\n",
              "  'contains(almost)': False,\n",
              "  'contains(also)': True,\n",
              "  'contains(although)': True,\n",
              "  'contains(another)': False,\n",
              "  'contains(around)': False,\n",
              "  'contains(audience)': True,\n",
              "  'contains(back)': True,\n",
              "  'contains(bad)': True,\n",
              "  'contains(best)': False,\n",
              "  'contains(better)': False,\n",
              "  'contains(big)': True,\n",
              "  'contains(cast)': False,\n",
              "  'contains(character)': True,\n",
              "  'contains(characters)': True,\n",
              "  'contains(come)': False,\n",
              "  'contains(comedy)': False,\n",
              "  'contains(could)': False,\n",
              "  'contains(director)': True,\n",
              "  'contains(end)': False,\n",
              "  'contains(enough)': False,\n",
              "  'contains(even)': True,\n",
              "  'contains(ever)': True,\n",
              "  'contains(every)': True,\n",
              "  'contains(fact)': False,\n",
              "  'contains(film)': True,\n",
              "  'contains(films)': True,\n",
              "  'contains(find)': True,\n",
              "  'contains(first)': False,\n",
              "  'contains(funny)': False,\n",
              "  'contains(get)': True,\n",
              "  'contains(gets)': False,\n",
              "  'contains(go)': True,\n",
              "  'contains(going)': True,\n",
              "  'contains(good)': True,\n",
              "  'contains(great)': False,\n",
              "  'contains(however)': False,\n",
              "  'contains(john)': False,\n",
              "  'contains(know)': True,\n",
              "  'contains(last)': False,\n",
              "  'contains(life)': True,\n",
              "  'contains(like)': True,\n",
              "  'contains(little)': True,\n",
              "  'contains(long)': False,\n",
              "  'contains(look)': True,\n",
              "  'contains(love)': False,\n",
              "  'contains(made)': False,\n",
              "  'contains(make)': True,\n",
              "  'contains(makes)': True,\n",
              "  'contains(man)': False,\n",
              "  'contains(many)': False,\n",
              "  'contains(may)': False,\n",
              "  'contains(movie)': True,\n",
              "  'contains(movies)': True,\n",
              "  'contains(much)': False,\n",
              "  \"contains(n't)\": True,\n",
              "  'contains(never)': False,\n",
              "  'contains(new)': True,\n",
              "  'contains(nothing)': False,\n",
              "  'contains(one)': True,\n",
              "  'contains(people)': True,\n",
              "  'contains(performance)': False,\n",
              "  'contains(played)': False,\n",
              "  'contains(plays)': False,\n",
              "  'contains(plot)': True,\n",
              "  'contains(real)': False,\n",
              "  'contains(really)': True,\n",
              "  'contains(right)': False,\n",
              "  'contains(role)': False,\n",
              "  'contains(say)': False,\n",
              "  'contains(scene)': False,\n",
              "  'contains(scenes)': True,\n",
              "  'contains(script)': False,\n",
              "  'contains(see)': True,\n",
              "  'contains(seems)': True,\n",
              "  'contains(seen)': False,\n",
              "  'contains(since)': True,\n",
              "  'contains(something)': False,\n",
              "  'contains(still)': True,\n",
              "  'contains(story)': False,\n",
              "  'contains(take)': False,\n",
              "  'contains(thing)': False,\n",
              "  'contains(things)': True,\n",
              "  'contains(think)': False,\n",
              "  'contains(though)': False,\n",
              "  'contains(time)': False,\n",
              "  'contains(two)': True,\n",
              "  'contains(us)': True,\n",
              "  'contains(way)': True,\n",
              "  'contains(well)': True,\n",
              "  'contains(work)': False,\n",
              "  'contains(world)': True,\n",
              "  'contains(would)': True,\n",
              "  'contains(years)': True,\n",
              "  'contains(young)': False},\n",
              " 'neg')"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "training_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH7PlErvi_Ln"
      },
      "source": [
        "`NLTK`'s Naive Bayes classifier can now be trained with this information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "AOpEj38Ei_Lo",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from nltk import NaiveBayesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "Rqvgo3ehi_Lo",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# We train by calling the .train() method with the just created training data\n",
        "\n",
        "nb = NaiveBayesClassifier.train(training_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoIrjBYNi_Lp"
      },
      "source": [
        "### Testing\n",
        "\n",
        "How can we test/run the classifier now?\n",
        "\n",
        "For text, we need to do the same things as above:\n",
        "\n",
        "1. Tokenization\n",
        "2. Feature Extraction\n",
        "3. Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "nOkyIa30i_Lp",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ea742f64-d5d2-4338-ab1f-eae09485196a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NaiveBayesClassifier.classify of <nltk.classify.naivebayes.NaiveBayesClassifier object at 0x7eb0c9341790>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.classify.naivebayes.NaiveBayesClassifier.classify</b><br/>def classify(featureset)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/nltk/classify/naivebayes.py</a>:return: the most appropriate label for the given featureset.\n",
              ":rtype: label</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 88);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "?nb.classify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct5HDmjrEBhP"
      },
      "source": [
        "#### TASK 1.4\n",
        "Write a function to test the classification.\n",
        "1. Tokenize\n",
        "2. Extract features\n",
        "3. Classification with nb.classify()\n",
        "4. Return Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "pS3KYk3wEBhP"
      },
      "outputs": [],
      "source": [
        "### IMPLEMENT YOUR SOLUTION HERE ###\n",
        "def test_classify(example):\n",
        "    return nb.classify(extract_features(tokenization(example)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "iU48tLUli_Lq",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a68e76d-89bf-4083-d476-f76320e4cdec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classifier predicts: neg\n"
          ]
        }
      ],
      "source": [
        "example = \"I really hate this movie. It is the worst movie that I have ever seen.\"\n",
        "\n",
        "output = test_classify(example)\n",
        "\n",
        "print(f\"The classifier predicts: {output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "evWR_Yu7i_Lq",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79aa564d-1f81-4bb8-c61a-04f60e1fab1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classifier predicts: pos\n"
          ]
        }
      ],
      "source": [
        "example = \"I liked the perfect character performance so much that I watched this great film almost a hundred times back to back and fell fully in love with the well-designed plot.\"\n",
        "\n",
        "output = test_classify(example)\n",
        "\n",
        "print(f\"The classifier predicts: {output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "5LSobKJui_Lq",
        "jupyter": {
          "outputs_hidden": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8405757a-3537-4fcc-e918-d026e7088131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "           contains(bad) = True              neg : pos    =      2.0 : 1.0\n",
            "        contains(script) = True              neg : pos    =      1.6 : 1.0\n",
            "          contains(life) = True              pos : neg    =      1.5 : 1.0\n",
            "       contains(nothing) = True              neg : pos    =      1.5 : 1.0\n",
            "           contains(bad) = False             pos : neg    =      1.5 : 1.0\n",
            "         contains(world) = True              pos : neg    =      1.5 : 1.0\n",
            "           contains(n't) = False             pos : neg    =      1.5 : 1.0\n",
            "   contains(performance) = True              pos : neg    =      1.4 : 1.0\n",
            "         contains(great) = True              pos : neg    =      1.4 : 1.0\n",
            "      contains(although) = True              pos : neg    =      1.4 : 1.0\n"
          ]
        }
      ],
      "source": [
        "nb.show_most_informative_features(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9i3xmcZi_Lq"
      },
      "source": [
        "From this view, we can see which *features* contributed to which *class*.\n",
        "\n",
        "Note, this is is purely (!) from the training data, there is nothing of world knowledge or semantics.\n",
        "\n",
        "From the first line, we can see that from the training data, if the text _contains_ the word \"bad\", it is 2 times more likely to be a _negative_ class. The combination of these probabilities lead to the output.\n",
        "\n",
        "The way this works is also by **negative** samples, for example, if the text **DOES NOT** contain the word \"bad\" (`contains(bad) = False`) it is additionally, 1.5 times more probable to belong to the _positive_ class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3RLKUFxi_Lq"
      },
      "source": [
        "## Future Work:\n",
        "\n",
        "Instead of using a simple boolean indicator, we could also use the number of appearances.\n",
        "\n",
        "We could introduce other features, maybe the length of the full text, the average word length, etc. And we could go through the vocabulary and remove more self-defined stopwords (e.g. \"would\" is not on the list). Also, it might make sense to not use the top-100 but the ones in the range between 101-200 or even further down.\n",
        "\n",
        "We'll get to that later."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "HSG_NLP_EDU",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}